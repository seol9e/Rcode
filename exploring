# Print the comics data
comics

# Check levels of align
levels(comics$align)

# Check the levels of gender
levels(comics$gender)

# Create a 2-way contingency table
table(comics$align,comics$gender)
# Load dplyr
library(dplyr)

# Print tab
tab

# Remove align level
comics_filtered <- comics%>%
  filter(align != "Reformed Criminals") %>%
  droplevels()

# See the result
comics_filtered
# Load ggplot2
library(ggplot2)

# Create side-by-side bar chart of gender by alignment
ggplot(comics, aes(x = align, fill = gender)) + 
  geom_bar(position = "dodge")

# Create side-by-side bar chart of alignment by gender
ggplot(comics, aes(x = gender, fill = align)) + 
  geom_bar(position="dodge") +
  theme(axis.text.x = element_text(angle = 90))
# Plot of gender by align
ggplot(comics, aes(x = align, fill = gender)) +
  geom_bar()
  
# Plot proportion of gender, conditional on align
ggplot(comics, aes(x = align, fill = gender)) + 
  geom_bar(position = "fill") +
  ylab("proportion")
# Change the order of the levels in align
comics$align <- factor(comics$align, 
                       levels = c("Bad", "Neutral", "Good"))

# Create plot of align
ggplot(comics, aes(x = align)) + 
  geom_bar()
# Plot of alignment broken down by gender
ggplot(comics, aes(x = align)) + 
  geom_bar() +
  facet_wrap(~ gender)
# Put levels of flavor in descending order
lev <- c("apple", "key lime", "boston creme", "blueberry", "cherry", "pumpkin", "strawberry")
pies$flavor <- factor(pies$flavor, levels = lev)

# Create bar chart of flavor
ggplot(pies, aes(x = flavor)) + 
  geom_bar(fill = "chartreuse") + 
  theme(axis.text.x = element_text(angle = 90))
# Load package

library(ggplot2)
# Learn data structure
str(cars)

# Create faceted histogram
ggplot(cars, aes(x = city_mpg)) +
  geom_histogram() +
  facet_wrap(~ suv)
# Filter cars with 4, 6, 8 cylinders
common_cyl <- filter(cars, ncyl%in%c(4,6,8))

# Create box plots of city mpg by ncyl
ggplot(common_cyl, aes(x = as.factor(ncyl), y = city_mpg)) +
  geom_boxplot()

# Create overlaid density plots for same data
ggplot(common_cyl, aes(x = city_mpg, fill = as.factor(ncyl))) +
  geom_density(alpha = .3)
# Create hist of horsepwr
cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram() +
  ggtitle("horsepwr")

# Create hist of horsepwr for affordable cars
cars %>% 
  filter(msrp<25000) %>%
  ggplot(aes(horsepwr)) +
  geom_histogram() +
  xlim(c(90, 550)) +
  ggtitle("horsepwr")
# Create hist of horsepwr with binwidth of 3
cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 3) +
  ggtitle("horsepwr")

# Create hist of horsepwr with binwidth of 30

cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 30) +
  ggtitle("horsepwr")
# Create hist of horsepwr with binwidth of 60

cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 60) +
  ggtitle("horsepwr")
# Construct box plot of msrp
cars %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()

# Exclude outliers from data
cars_no_out <- cars %>%
  filter(msrp<100000)

# Construct box plot of msrp using the reduced dataset
cars_no_out %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()
# Create plot of city_mpg
cars %>%
  ggplot(aes(x =1,y= city_mpg)) +
  geom_boxplot() 

# Create plot of width
cars %>% 
  ggplot(aes(x = width)) +
  geom_density()
# Facet hists using hwy mileage and ncyl
common_cyl %>%
  ggplot(aes(x = hwy_mpg)) +
  geom_histogram() +
  facet_grid(ncyl ~ suv) +
  ggtitle("ncul vs suv")
# Create dataset of 2007 data
gap2007 <- filter(gapminder, year==2007)

# Compute groupwise mean and median lifeExp
gap2007 %>%
  group_by(continent) %>%
  summarize(mean(lifeExp),
            median(lifeExp))

# Generate box plots of lifeExp for each continent
gap2007 %>%
  ggplot(aes(x = continent, y = lifeExp)) +
  geom_boxplot()
# Compute groupwise measures of spread
gap2007 %>%
  group_by(continent) %>%
  summarize(sd(lifeExp),
            IQR(lifeExp),
            n())

# Generate overlaid density plots
gap2007 %>%
  ggplot(aes(x = lifeExp, fill = continent)) +
  geom_density(alpha = 0.3)
# Compute stats for lifeExp in Americas
gap2007 %>%
  filter(continent=="Americas") %>%
  summarize(mean(lifeExp),
            sd(lifeExp))

# Compute stats for population
gap2007 %>%
  summarize(median(pop),
            IQR(pop))
# Create density plot of old variable
gap2007 %>%
  ggplot(aes(x = pop)) +
  geom_density()

# Transform the skewed pop variable
gap2007 <- gap2007 %>%
  mutate(log_pop=log(pop))

# Create density plot of new variable
gap2007 %>%
  ggplot(aes(x =log_pop )) +
geom_density()
# Filter for Asia, add column indicating outliers
gap_asia <- gap2007 %>%
  filter(continent=="Asia") %>%
  mutate(is_outlier = ifelse(lifeExp<50, TRUE, FALSE))

# Remove outliers, create box plot of lifeExp
gap_asia %>%
  filter(is_outlier==FALSE) %>%
  ggplot(aes(x =1 , y = lifeExp)) +
  geom_boxplot()
# Load packages
library(ggplot2)
library(dplyr)
library(openintro)

# Compute summary statistics
email %>%
  group_by(spam) %>%
  summarize(median(num_char),IQR(num_char))

# Create plot
email %>%
  mutate(log_num_char = log(num_char)) %>%
  ggplot(aes(x =spam , y = log_num_char)) +
  geom_boxplot()
# Compute center and spread for exclaim_mess by spam
email%>%
group_by(spam)%>%
summarize(IQR(exclaim_mess),median(exclaim_mess))



# Create plot for spam and exclaim_mess
email%>%
mutate(log_exclaim_mess=log(exclaim_mess+0.01))%>%
ggplot( aes(x=spam,y=log_exclaim_mess))+geom_density()
# Create plot of proportion of spam by image
email %>%
  mutate(has_image=image>0) %>%
  ggplot(aes(x = has_image,fill = spam)) +
  geom_bar(position = "fill")
# Test if images count as attachments
sum(email$image >  email$attach)
# Question 1
email %>%
  filter(dollar>0) %>%
  group_by(spam) %>%
  summarize(median_dollar=median(dollar))

# Question 2
email %>%
  filter(dollar>10) %>%
  ggplot(aes(x = spam)) +
  geom_bar()
# Reorder levels
email$number_reordered <- factor(email$number,levels=c("none","small","big"))

# Construct plot of number_reordered
ggplot(email, aes(number_reordered))+geom_bar()+facet_wrap(~ spam)
# From previous steps
mdl_price_vs_dist <- lm(
  price_twd_msq ~ sqrt(dist_to_mrt_m), 
  data = taiwan_real_estate
)
explanatory_data <- tibble(
  dist_to_mrt_m = seq(0, 80, 10) ^ 2
)
prediction_data <- explanatory_data %>% 
  mutate(
    price_twd_msq = predict(mdl_price_vs_dist, explanatory_data)
  )

ggplot(taiwan_real_estate, aes(sqrt(dist_to_mrt_m), price_twd_msq)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  # Add points from prediction_data, colored green, size 5
  geom_point(data=prediction_data, color="green",size=5)
# From previous steps
mdl_click_vs_impression <- lm(
  I(n_clicks ^ 0.25) ~ I(n_impressions ^ 0.25),
  data = ad_conversion
)
explanatory_data <- tibble(
  n_impressions = seq(0, 3e6, 5e5)
)
prediction_data <- explanatory_data %>% 
  mutate(
    n_clicks_025 = predict(mdl_click_vs_impression, explanatory_data),
    n_clicks = n_clicks_025 ^ 4
  )

ggplot(ad_conversion, aes(n_impressions ^ 0.25, n_clicks ^ 0.25)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  # Add points from prediction_data, colored green
  geom_point(data=prediction_data,color="green")

glance(mdl_click_vs_impression_orig) %>% 
  # Pull out r.squared
  pull(r.squared)

script.R
1
R Console
Slides
Notes
>
summary(mdl_click_vs_impression_orig)
# Get RSE for mdl_click_vs_impression_orig
mdl_click_vs_impression_orig %>% 
  # Get the model-level details
  glance() %>% 
  # Pull out sigma
  pull(sigma)
[1] 19.90584
# Do the same for the transformed model
# Get RSE for mdl_click_vs_impression_orig
mdl_click_vs_impression_trans%>% 
  # Get the model-level details
  glance() %>% 
  # Pull out sigma
  pull(sigma)
[1] 0.1969064
# Plot the three diagnostics for mdl_price_vs_conv
autoplot(mdl_price_vs_conv, which=1:3,nrow=3, ncol=1)
mdl_price_vs_dist %>% 
  # Augment the model
  augment() %>% 
  # Arrange rows by descending leverage
  arrange(desc(.hat))%>% 
  # Get the head of the dataset
  head()
mdl_price_vs_dist %>% 
  # Augment the model
  augment()%>% 
  # Arrange rows by descending Cook's distance
  arrange(desc(.cooksd)) %>% 
  # Get the head of the dataset
  head()
# Plot the three outlier diagnostics for mdl_price_vs_dist
autoplot(mdl_price_vs_dist,which=4:6,nrow=3,ncol=1)
# Using churn, plot time_since_last_purchase
ggplot(churn, aes(time_since_last_purchase)) +
  # as a histogram with binwidth 0.25
  geom_histogram(binwidth=0.25) +
  # faceted in a grid with has_churned on each row
  facet_grid(rows=vars(has_churned))
# Redraw the plot with time_since_first_purchase
ggplot(churn, aes(time_since_first_purchase)) +
  # as a histogram with binwidth 0.25
  geom_histogram(binwidth=0.25) +
  # faceted in a grid with has_churned on each row
  facet_grid(rows=vars(has_churned))
ggplot(churn, aes(time_since_first_purchase, has_churned)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  # Add a glm trend line, no std error ribbon, binomial family
  geom_smooth(method="glm", se=FALSE, method.args=list(family=binomial))
# Fit a logistic regression of churn vs. length of relationship using the churn dataset
mdl_churn_vs_relationship <- glm(has_churned~time_since_first_purchase, data=churn, family=binomial)

# See the result
mdl_churn_vs_relationship
# Update the plot
plt_churn_vs_relationship +
  # Add points from prediction_data, colored yellow, size 2
  geom_point(data=prediction_data,color="yellow",size=2)
